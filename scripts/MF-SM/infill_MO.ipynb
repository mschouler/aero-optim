{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Infill NOTEBOOK\n",
    "\n",
    "This notebook validates the Bayesian multi-objective adaptive infill strategy.\n",
    "\n",
    "**Notes**: the tests are performed for multi-fidelity multi-objective optimization similarly to work from Charayron et al. [(1)](https://www.sciencedirect.com/science/article/pii/S1270963823005692?via%3Dihub)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Any\n",
    "\n",
    "from aero_optim.mf_sm.mf_models import get_model, get_sampler, MultiObjectiveModel, MfDNN, MfSMT\n",
    "from aero_optim.mf_sm.mf_infill import compute_pareto, minimize_LCB, maximize_ED, maximize_MPI_BO, maximize_PI_BO\n",
    "from pymoo.problems import get_problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZDT1 multi-fidelity multi-objective functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_hf(x):\n",
    "    f1 = x[:, 0]\n",
    "    return f1\n",
    "\n",
    "def f2_hf(x):\n",
    "    n_var = x.shape[-1]\n",
    "    u = 1 + 9.0 / (n_var - 1) * np.sum(x[:, 1:], axis=1)\n",
    "    v = 1 - np.sqrt(f1_hf(x) / u)\n",
    "    f2 = u * v\n",
    "    return f2\n",
    "\n",
    "def f_hf(x):\n",
    "    return np.column_stack([f1_hf(x), f2_hf(x)])\n",
    "\n",
    "def f1_lf(x):\n",
    "    f1 = 0.9 * x[:, 0] + 0.1\n",
    "    return f1\n",
    "\n",
    "def f2_lf(x):\n",
    "    n_var = x.shape[-1]\n",
    "    u = 1 + 9.0 / (n_var - 1) * np.sum(x[:, 1:], axis=1)\n",
    "    v = 1 - np.sqrt(f1_hf(x) / u)\n",
    "    return (0.8 * u - 0.2) * (1.2 * v + 0.2)\n",
    "\n",
    "def f_lf(x):\n",
    "    return np.column_stack([f1_lf(x), f2_lf(x)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian infill sample computation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bayesian_infill(\n",
    "        model: MfDNN | MultiObjectiveModel,\n",
    "        infill_lf_size: int,\n",
    "        infill_nb_gen: int,\n",
    "        n_design: int,\n",
    "        bound: tuple[Any],\n",
    "        seed: int\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    **Computes** the low fidelity Bayesian infill candidates.\n",
    "    \"\"\"\n",
    "    assert isinstance(model, MultiObjectiveModel)\n",
    "    # Probability of Improvement\n",
    "    infill_lf = maximize_MPI_BO(model, n_design, bound, seed, infill_nb_gen)\n",
    "    # Lower Confidence Bound /objective 1\n",
    "    assert isinstance(model.models[0], MfSMT)\n",
    "    infill_lf_LCB_1 = minimize_LCB(model.models[0], n_design, bound, seed, infill_nb_gen)\n",
    "    infill_lf = np.vstack((infill_lf, infill_lf_LCB_1))\n",
    "    # Lower Confidence Bound /objective 2\n",
    "    assert isinstance(model.models[1], MfSMT)\n",
    "    infill_lf_LCB_2 = minimize_LCB(model.models[1], n_design, bound, seed, infill_nb_gen)\n",
    "    infill_lf = np.vstack((infill_lf, infill_lf_LCB_2))\n",
    "    # max-min Euclidean Distance\n",
    "    current_DOE = model.get_DOE()\n",
    "    current_DOE = np.vstack((current_DOE, infill_lf))\n",
    "    for _ in range(infill_lf_size - 3):\n",
    "        infill_lf_ED = maximize_ED(current_DOE, n_design, bound, seed, infill_nb_gen)\n",
    "        infill_lf = np.vstack((infill_lf, infill_lf_ED))\n",
    "        current_DOE = np.vstack((current_DOE, infill_lf_ED))\n",
    "    return infill_lf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Custom Bayesian infill strategy\n",
    "\n",
    "The Bayesian infill input variables are:\n",
    "\n",
    "- `seed` the random seed\n",
    "- `dim` the dimension of the problem\n",
    "- `n_lf` the number of initial low-fidelity samples to draw\n",
    "- `n_hf` the number of initial high-fidelity samples to draw\n",
    "- `n_iter` the number of infill steps\n",
    "- `infill_lf_size` the number of low-fidelity samples to compute at each infill step\n",
    "- `infill_nb_gen` the number of generations of the sub-optimization executions\n",
    "\n",
    "**Note**: the low- / high-fidelity infill ratio is 10 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "dim = 6\n",
    "n_lf = 12\n",
    "n_hf = 6\n",
    "n_iter = 15\n",
    "infill_lf_size = 10\n",
    "infill_nb_gen = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Builds the nested LHS sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_sampler = get_sampler(dim, bounds=[0, 1], seed=seed, nested_doe=True)\n",
    "x_lf, x_hf = mf_sampler.sample_mf(n_lf, n_hf)\n",
    "y_lf = f_lf(x_lf)\n",
    "y_hf = f_hf(x_hf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Builds the multi-objective co-kriging model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = get_model(model_name=\"mfsmt\", dim=dim, config_dict={}, outdir=\"\", seed=seed)\n",
    "model2 = get_model(model_name=\"mfsmt\", dim=dim, config_dict={}, outdir=\"\", seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo_model = MultiObjectiveModel([model1, model2])\n",
    "mo_model.set_DOE(x_lf=x_lf, x_hf=x_hf, y_lf=[y_lf[:, 0], y_lf[:, 1]], y_hf=[y_hf[:, 0], y_hf[:, 1]])\n",
    "mo_model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian adaptive infill loop\n",
    "\n",
    "**Note**: this should take around 4 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bound = [0, 1]\n",
    "pareto_list = [compute_pareto(mo_model.models[0].y_hf_DOE, mo_model.models[1].y_hf_DOE)]\n",
    "for _ in range(n_iter):\n",
    "    x_lf_infill = compute_bayesian_infill(mo_model, infill_lf_size, infill_nb_gen, dim, bound, seed)\n",
    "    y_lf_infill = f_lf(x_lf_infill)\n",
    "    x_hf_infill = x_lf_infill[0]\n",
    "    y_hf_infill = f_hf(x_hf_infill.reshape(1, -1))\n",
    "    print(f\"iter {_}, new x_f {x_hf_infill}, new y_hf {y_hf_infill}\")\n",
    "    mo_model.set_DOE(x_lf=x_lf_infill, y_lf=[y_lf_infill[:, 0], y_lf_infill[: ,1]], x_hf=x_hf_infill, y_hf=[y_hf_infill[:, 0], y_hf_infill[:, 1]])\n",
    "    mo_model.train()\n",
    "    print(\"model retrained\")\n",
    "    pareto_list.append(compute_pareto(mo_model.models[0].y_hf_DOE, mo_model.models[1].y_hf_DOE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the analytical Pareto front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = get_problem(\"zdt1\")\n",
    "true_pareto = problem.pareto_front()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian adaptive infill results are plotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(true_pareto[:, 0], true_pareto[:, 1], color=\"r\", label=\"true pareto\")\n",
    "cm = plt.get_cmap('viridis')\n",
    "COLORS = [cm(ii * 10) for ii in range(len(pareto_list) + 1)]\n",
    "ax.scatter(pareto_list[-1][:, 0], pareto_list[-1][:, 1], color=COLORS[-1], marker=\"d\", label=\"final Pareto\")\n",
    "ax.scatter(mo_model.models[0].y_hf_DOE[:n_hf], mo_model.models[1].y_hf_DOE[:n_hf], color=\"k\", facecolors=\"None\", label=\"initial DOE\")\n",
    "ax.scatter(mo_model.models[0].y_hf_DOE[n_hf:], mo_model.models[1].y_hf_DOE[n_hf:], color=\"r\", facecolors=\"None\", label=\"hf infills\")\n",
    "ax.set(xlabel='$y_1$', ylabel='$y_2$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Maximal Probability of Improvement infill strategy\n",
    "\n",
    "The MPI infill input variables are:\n",
    "\n",
    "- `seed` the random seed\n",
    "- `dim` the dimension of the problem\n",
    "- `n_lf` the number of initial low-fidelity samples to draw\n",
    "- `n_hf` the number of initial high-fidelity samples to draw\n",
    "- `n_iter` the number of infill steps\n",
    "- `infill_nb_gen` the number of generations of the sub-optimization executions\n",
    "\n",
    "**Note**: at each step a unique low- and high-fidelity sample is computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "dim = 6\n",
    "n_lf = 12\n",
    "n_hf = 6\n",
    "n_iter = 15\n",
    "infill_nb_gen = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Builds the nested LHS sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_sampler = get_sampler(dim, bounds=[0, 1], seed=seed, nested_doe=True)\n",
    "x_lf, x_hf = mf_sampler.sample_mf(n_lf, n_hf)\n",
    "y_lf = f_lf(x_lf)\n",
    "y_hf = f_hf(x_hf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Builds the multi-objective co-kriging model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = get_model(model_name=\"mfsmt\", dim=dim, config_dict={}, outdir=\"\", seed=seed)\n",
    "model2 = get_model(model_name=\"mfsmt\", dim=dim, config_dict={}, outdir=\"\", seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo_model = MultiObjectiveModel([model1, model2])\n",
    "mo_model.set_DOE(x_lf=x_lf, x_hf=x_hf, y_lf=[y_lf[:, 0], y_lf[:, 1]], y_hf=[y_hf[:, 0], y_hf[:, 1]])\n",
    "mo_model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MPI adaptive infill loop\n",
    "\n",
    "**Note**: this should take around 1 minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bound = [0, 1]\n",
    "pareto_list = [compute_pareto(mo_model.models[0].y_hf_DOE, mo_model.models[1].y_hf_DOE)]\n",
    "for _ in range(n_iter):\n",
    "    x_lf_infill = maximize_MPI_BO(mo_model, dim, bound, seed, infill_nb_gen)\n",
    "    y_lf_infill = f_lf(x_lf_infill.reshape(1, -1))\n",
    "    x_hf_infill = x_lf_infill\n",
    "    y_hf_infill = f_hf(x_hf_infill.reshape(1, -1))\n",
    "    print(f\"iter {_}, new x_f {x_hf_infill}, new y_hf {y_hf_infill}\")\n",
    "    mo_model.set_DOE(x_lf=x_lf_infill, y_lf=[y_lf_infill[:, 0], y_lf_infill[: ,1]], x_hf=x_hf_infill, y_hf=[y_hf_infill[:, 0], y_hf_infill[:, 1]])\n",
    "    mo_model.train()\n",
    "    print(\"model retrained\")\n",
    "    pareto_list.append(compute_pareto(mo_model.models[0].y_hf_DOE, mo_model.models[1].y_hf_DOE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MPI adaptive infill results are plotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(true_pareto[:, 0], true_pareto[:, 1], color=\"r\", label=\"true pareto\")\n",
    "cm = plt.get_cmap('viridis')\n",
    "COLORS = [cm(ii * 10) for ii in range(len(pareto_list) + 1)]\n",
    "ax.scatter(pareto_list[-1][:, 0], pareto_list[-1][:, 1], color=COLORS[-1], marker=\"d\", label=\"final pareto\")\n",
    "ax.scatter(mo_model.models[0].y_hf_DOE[:n_hf], mo_model.models[1].y_hf_DOE[:n_hf], color=\"k\", facecolors=\"None\", label=\"initial DOE\")\n",
    "ax.scatter(mo_model.models[0].y_hf_DOE[n_hf:], mo_model.models[1].y_hf_DOE[n_hf:], color=\"r\", facecolors=\"None\", label=\"infill\")\n",
    "ax.set(xlabel='$y_1$', ylabel='$y_2$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
