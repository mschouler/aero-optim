{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VAE NOTEBOOK\n",
    "\n",
    "This notebook applies VAE-coupled FFD to a geometry and illustrates various reconstruction aspects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "\n",
    "from scipy.stats import qmc, norm\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from aero_optim.geom import get_curvature\n",
    "from aero_optim.ffd.ffd import FFD_2D\n",
    "from aero_optim.ffd.ffd_vae_models import MLPEncoder, MLPDecoder, CNNEncoder, CNNDecoder, VAE, VAETrainer\n",
    "\n",
    "# Latex consistent figures\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"Times\",\n",
    "    \"figure.dpi\": 300,\n",
    "    \"font.size\": 8,\n",
    "    'legend.fontsize': 8, \n",
    "    \"axes.titlesize\": 8,\n",
    "    \"axes.labelsize\": 8\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook input variables are:\n",
    "\n",
    "- `seed` the sampling seed \n",
    "- `ncontrol` the number of FFD control points on each side of the lattice box\n",
    "- `bounds` the FFD deformation boundaries\n",
    "- `nprofile` the number of FFD deformed profiles used to build the FFD dataset\n",
    "- `latent_dim`Â the latent space dimension of the VAE model\n",
    "- `file` the path to the file containing the geometry coordinates\n",
    "\n",
    "**Note**: the number of FFD design variables is `2 * ncontrol`, the number of VAE design variables is `latent_dim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "torch.manual_seed(seed)\n",
    "ncontrol = 4\n",
    "bounds = (-0.2, 0.2)\n",
    "nprofile = 1000\n",
    "latent_dim = 4\n",
    "file = \"/home/mschouler/Documents/Sorbonne/aero-optim/examples/RAE2822/data/rae2822.dat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `FFD_2D` object is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffd = FFD_2D(file, ncontrol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random LHS sampler is built and used to sample the FFD dataset\n",
    "\n",
    "**Note**: this should take between 5 (RAE2822) to 10 (LRN-CASCADE) seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = qmc.LatinHypercube(d=int(2 * ncontrol), seed=seed)\n",
    "train_sample = sampler.random(n=nprofile)\n",
    "train_sample = qmc.scale(train_sample, *bounds)\n",
    "val_sample = sampler.random(n=int(0.2 * nprofile))\n",
    "val_sample = qmc.scale(val_sample, *bounds)\n",
    "\n",
    "profiles = []\n",
    "for Delta in train_sample:\n",
    "    profiles.append(ffd.apply_ffd(Delta))\n",
    "for Delta in val_sample:\n",
    "    profiles.append(ffd.apply_ffd(Delta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The VAE training and evaluation datasets are generated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y  = np.stack([p[:, -1] for p in profiles] , axis=0, dtype=np.float32)\n",
    "print(f\"Y shape: {Y.shape}\")\n",
    "\n",
    "Y_train = Y[:nprofile]\n",
    "Y_val = Y[nprofile:]\n",
    "\n",
    "mean = np.mean(Y_train, axis=0)\n",
    "std = np.std(Y_train, axis=0) + 1e-6\n",
    "\n",
    "Y_train = (Y_train - mean) / std\n",
    "Y_val = (Y_val - mean) / std\n",
    "\n",
    "Y_train_torch = torch.from_numpy(Y_train.astype(np.float32))\n",
    "Y_val_torch = torch.from_numpy(Y_val.astype(np.float32))\n",
    "\n",
    "train_set = TensorDataset(Y_train_torch)\n",
    "val_set = TensorDataset(Y_val_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The VAE model is defined with MLP or CNN achitectures:\n",
    "\n",
    "- `inner_dim` the number of neurones per hidden layer for the models dense layers \n",
    "- `w_kl` the weight of the Kullback Leibler divergence loss\n",
    "- `encoder` the encoder model\n",
    "- `decoder` the decoder model\n",
    "- `VAEmodel` the VAE model\n",
    "- `optimizer` the VAE optimizer\n",
    "- `batch_size` the bastch size of the dataloaders\n",
    "- `epochs` the number of training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = profiles[0].shape[0]\n",
    "inner_dim = [512, 256, 128]\n",
    "w_kl = 1e-4\n",
    "\n",
    "encoder = MLPEncoder(input_dim, inner_dim, latent_dim, torch.nn.SiLU(), batch_norm=True)\n",
    "decoder = MLPDecoder(input_dim, inner_dim, latent_dim, torch.nn.SiLU(), batch_norm=True)\n",
    "\n",
    "# encoder = CNNEncoder(input_dim, latent_dim, torch.nn.functional.silu, kernel_size=10)\n",
    "# decoder = CNNDecoder(encoder.lin_dim, latent_dim, torch.nn.functional.silu, kernel_size=10)\n",
    "\n",
    "VAEmodel = VAE(encoder, decoder, w_kl=w_kl)\n",
    "VAEmodel.to(VAEmodel.device)\n",
    "optimizer = torch.optim.AdamW(VAEmodel.parameters(), lr=1e-3, weight_decay=1e-2)\n",
    "\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_set, shuffle=True, batch_size=batch_size)\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is trained in 10 steps and the reconstruction error is computed at each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = VAETrainer(VAEmodel, optimizer)\n",
    "errors = []\n",
    "\n",
    "for i in range(10):\n",
    "    trainer.train(train_loader, val_loader, epochs // 10)\n",
    "    VAEmodel.eval()\n",
    "    Y_pred = VAEmodel(Y_train_torch.to(VAEmodel.device)).x_recon.detach().cpu().numpy() * std + mean\n",
    "    error = np.sqrt(\n",
    "        np.sum(\n",
    "            [np.sum((y_pred - y_true)**2)\n",
    "             for y_pred, y_true in zip(Y_pred, Y_train * std + mean)]\n",
    "        ) / nprofile\n",
    "    )\n",
    "    errors.append(error)\n",
    "    print(f\"reconstruction error after {(i + 1) * epochs // 10} epochs: {error}\")\n",
    "\n",
    "train_losses = trainer.train_losses\n",
    "val_losses = trainer.val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The losses and the reconstruction errors are plotted\n",
    "\n",
    "**Note**: the POD reconstruction error `POD_error` can be specified here if the POD notebook was executed first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POD_error = None\n",
    "\n",
    "_, ax = plt.subplots(2, 1, figsize=(3.65, 3.65), sharex=True)\n",
    "ax[0].plot(range(1, epochs * len(train_loader) + 1), train_losses, label=\"training loss\")\n",
    "ax[0].plot([ii * len(train_loader) for ii in range(1, epochs + 1)], val_losses, label=\"validation loss\")\n",
    "ax[0].set_yscale(\"log\")\n",
    "\n",
    "ax[1].set_ylabel(\"RMSE [m]\")\n",
    "if POD_error:\n",
    "    ax[1].hlines(\n",
    "        y=POD_error, xmin=epochs // 10 * len(train_loader),\n",
    "        xmax=epochs * len(train_loader) + 1,\n",
    "        color='lightgray', linestyle='-', label=\"POD\"\n",
    "    )\n",
    "ax[1].plot(\n",
    "    range(epochs // 10 * len(train_loader), epochs * len(train_loader) + 1, epochs // 10 * len(train_loader)),\n",
    "    errors, color=\"r\", marker=\"s\", label=\"VAE\"\n",
    ")\n",
    "\n",
    "ax[0].legend(loc=\"upper right\")\n",
    "ax[0].set(ylabel=f'MSE + ${w_kl}\\\\times KL$ $[-]$')\n",
    "ax[1].legend(loc=\"upper right\")\n",
    "ax[1].set(xlabel=\"batch $[-]$\", )\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random profiles from the FFD dataset and their reduced reconstruction are plotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3.64, 2))\n",
    "for ii in range(5):\n",
    "    idx = random.randint(0, nprofile - 1)\n",
    "    plt.plot(ffd.pts[:, 0], Y_train[idx] * std + mean)\n",
    "    plt.plot(ffd.pts[:, 0], Y_pred[idx], linestyle=\"dashed\", color=\"k\")\n",
    "ax.set(xlabel=\"$x$ [m]\", ylabel=\"$y$ [m]\", title=f\"Reconstructed profiles with {latent_dim} latent dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The VAE boundaries are inferred from the modal coefficient min/max values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAEmodel.eval()\n",
    "latent_space = VAEmodel.encoder(Y_train_torch.to(VAEmodel.device)).detach().cpu().numpy()\n",
    "\n",
    "l_bound = np.array([min(v) for v in latent_space.transpose()[:latent_dim]])\n",
    "u_bound = np.array([max(v) for v in latent_space.transpose()[:latent_dim]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The non-conservation of the FFD maximal deformations is illustrated with non-constrained LHS sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_profile = ffd.apply_ffd(np.array([bounds[0]] * 2 * ncontrol))\n",
    "max_profile = ffd.apply_ffd(np.array([bounds[-1]] * 2 * ncontrol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bounds = (l_bound, u_bound)\n",
    "new_sampler = qmc.LatinHypercube(d=latent_dim, seed=seed)\n",
    "new_sample = new_sampler.random(n=100)\n",
    "lhs_sample = qmc.scale(new_sample, *new_bounds)\n",
    "\n",
    "lhs_output = VAEmodel.decoder(torch.from_numpy(lhs_sample.astype(np.float32)).to(VAEmodel.device)).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3.15, 2))\n",
    "for out_id, out in enumerate(lhs_output):\n",
    "    if out_id == 0:\n",
    "        plt.plot(\n",
    "            ffd.pts[:, 0], out * std + mean,\n",
    "            linestyle=\"solid\", color=\"lightgrey\", linewidth=0.5, label=\"random VAE profiles\"\n",
    "        )\n",
    "    else:\n",
    "        plt.plot(ffd.pts[:, 0], out * std + mean, linestyle=\"solid\", color=\"lightgrey\", linewidth=0.5)\n",
    "plt.plot(ffd.pts[:, 0], ffd.pts[:, 1], color=\"k\", label=\"baseline\", linewidth=0.5)\n",
    "ax.plot(min_profile[:, 0], min_profile[:, 1], color=\"k\", linewidth=1, linestyle=\"dashed\", label=\"min/max FFD profiles\")\n",
    "ax.plot(max_profile[:, 0], max_profile[:, 1], color=\"k\", linewidth=1, linestyle=\"dashed\")\n",
    "ax.legend()\n",
    "ax.set(xlabel=\"$x$ [m]\", ylabel=\"$y$ [m]\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smooth but similar reduced profiles are obtained via constrained LHS sampling i.e. within one standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_mean = np.mean(latent_space[:, :latent_dim], axis=0)\n",
    "d_std = np.std(latent_space[:, :latent_dim], axis=0)\n",
    "\n",
    "new_bounds = (d_mean - d_std, d_mean + d_std)\n",
    "c_lhs_sample = qmc.scale(new_sample, *new_bounds)\n",
    "\n",
    "c_lhs_output = VAEmodel.decoder(torch.from_numpy(c_lhs_sample.astype(np.float32)).to(VAEmodel.device)).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3.15, 2))\n",
    "for out_id, out in enumerate(c_lhs_output):\n",
    "    if out_id == 0:\n",
    "        plt.plot(\n",
    "            ffd.pts[:, 0], out * std + mean,\n",
    "            linestyle=\"solid\", color=\"lightgrey\", linewidth=0.5, label=\"random VAE profiles\"\n",
    "        )\n",
    "    else:\n",
    "        plt.plot(ffd.pts[:, 0], out * std + mean, linestyle=\"solid\", color=\"lightgrey\", linewidth=0.5)\n",
    "plt.plot(ffd.pts[:, 0], ffd.pts[:, 1], color=\"k\", label=\"baseline\", linewidth=0.5)\n",
    "ax.plot(min_profile[:, 0], min_profile[:, 1], color=\"k\", linewidth=1, linestyle=\"dashed\", label=\"min/max FFD profiles\")\n",
    "ax.plot(max_profile[:, 0], max_profile[:, 1], color=\"k\", linewidth=1, linestyle=\"dashed\")\n",
    "ax.legend()\n",
    "ax.set(xlabel=\"$x$ [m]\", ylabel=\"$y$ [m]\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of 32 VAE reduced profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 8, figsize=(10, 5))\n",
    "\n",
    "for ii, aa in enumerate(ax):\n",
    "    for jj, bb in enumerate(aa):\n",
    "        bb.plot(ffd.pts[:, 0], c_lhs_output[ii * 8 + jj] * std + mean, color=\"k\", linewidth=2)\n",
    "        bb.axis(\"off\")\n",
    "        bb.set_aspect(4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The latent space distributions are plotted\n",
    "\n",
    "**Note**: if the latent space dimension `latent_dim` is changed, the sub-figure structure must be adapted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_norm(bin_borders, latent_space):\n",
    "    (mu, sigma) = norm.fit(latent_space)\n",
    "    print(f\"Normal curve fit popt {mu}, {sigma}\")\n",
    "    x = np.linspace(bin_borders[0], bin_borders[-1], 10000)\n",
    "    y = norm.pdf(x, mu, sigma)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4.5, 4.5))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "ax1 = plt.subplot(2, 2, 1)  # dim 1\n",
    "ax2 = plt.subplot(2, 2, 2)  # dim 2\n",
    "ax3 = plt.subplot(2, 2, 3)  # dim 3\n",
    "ax4 = plt.subplot(2, 2, 4)  # dim 4\n",
    "# ax1\n",
    "n, bins, _ = ax1.hist(latent_space[:, 0], bins=20, density=1, linewidth=0.5, edgecolor=\"white\")\n",
    "# fit\n",
    "x, y = fit_norm(bins, latent_space[:, 0])\n",
    "ax1.plot(x, y, 'r--', linewidth=2)\n",
    "ax1.set(xlabel=\"$\\\\alpha_1$ [-]\", ylabel=\"$N$ [-]\", title=\"a) distribution /dim 1\")\n",
    "\n",
    "# ax2\n",
    "n, bins, _ = ax2.hist(latent_space[:, 1], bins=20, density=1, linewidth=0.5, edgecolor=\"white\")\n",
    "x, y = fit_norm(bins, latent_space[:, 1])\n",
    "ax2.plot(x, y, 'r--', linewidth=2)\n",
    "ax2.set(xlabel=\"$\\\\alpha_2$ [-]\", ylabel=\"$N$ [-]\", title=\"a) distribution /dim 2\")\n",
    "\n",
    "# ax3\n",
    "bin_heights, bin_borders, _ = ax3.hist(latent_space[:, 2], bins=20, density=1, linewidth=0.5, edgecolor=\"white\")\n",
    "x, y = fit_norm(bin_borders, latent_space[:, 2])\n",
    "ax3.plot(x, y, 'r--', linewidth=2)\n",
    "ax3.set(xlabel=\"$\\\\alpha_3$ [-]\", ylabel=\"$N$ [-]\", title=\"a) distribution /dim 3\")\n",
    "\n",
    "# ax4\n",
    "bin_heights, bin_borders, _ = ax4.hist(latent_space[:, 3], bins=20, density=1, linewidth=0.5, edgecolor=\"white\")\n",
    "x, y = fit_norm(bin_borders, latent_space[:, 3])\n",
    "ax4.plot(x, y, 'r--', linewidth=2)\n",
    "ax4.set(xlabel=\"$\\\\alpha_4$ [-]\", ylabel=\"$N$ [-]\", title=\"a) distribution /dim 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAE reduced profiles curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = random.randint(0, len(c_lhs_output) - 1)\n",
    "y = c_lhs_output[idx] * std + mean\n",
    "\n",
    "# Compute curvature\n",
    "bsl_curvature = get_curvature(ffd.pts)\n",
    "vae_curvature = get_curvature(np.column_stack([ffd.pts[:, 0], y]))\n",
    "\n",
    "# Plot curvature\n",
    "fig, ax = plt.subplots(2, 1, figsize=(3.65, 3.65))\n",
    "ax[0].plot(ffd.pts[:, 0], ffd.pts[:, 1], color='b', label='baseline shape')\n",
    "ax[0].plot(ffd.pts[:, 0], y, color='r', label='VAE shape')\n",
    "ax[0].legend()\n",
    "ax[0].set_ylabel('$y$ [m]')\n",
    "\n",
    "ax[1].plot(ffd.pts[:, 0], bsl_curvature, label='baseline curvature', color='b')\n",
    "ax[1].plot(ffd.pts[:, 0], vae_curvature, label='VAE curvature', color='r')\n",
    "ax[1].set_yscale('log')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel('$x$ [m]')\n",
    "ax[1].set_ylabel('curvature [m$^{-1}$]')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
